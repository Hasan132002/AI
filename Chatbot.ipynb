{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hasan132002/AI/blob/main/Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "Chatbot Processes\n",
        "library\n",
        "data set processing\n",
        "define intent\n",
        "building training dataset\n",
        "extraction -> classifier -> naviesbayes\n",
        "define response\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "hdHewiocw3_c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Install and Import Library Nltk**"
      ],
      "metadata": {
        "id": "EE-SpUSR9nsx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUzn0d-o9uS9",
        "outputId": "8983672c-e6b2-4418-b98f-63abc304a77d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "D7ionR4m9_s-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**donwloading resource from nltk **"
      ],
      "metadata": {
        "id": "R-FU9uZC-DCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dn7x9J4r-Z4F",
        "outputId": "47cad0d7-b1bc-46b9-9142-7edaff8a4608"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "text='tata'"
      ],
      "metadata": {
        "id": "ZlD1SE9r-tJk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens=word_tokenize(text)"
      ],
      "metadata": {
        "id": "XfZKZLrkALmN"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intents = {\n",
        "    'greeting':['salam','hello','hey','oe','bhai','bhaya'],\n",
        "    'goodbye':['bye','tata','goodbye','seeyou'],\n",
        "    'question':['aik swal ha','question','i have a question','aik swal pocho'],\n",
        "\n",
        "}\n",
        "\n",
        "responses = {\n",
        "    'greeting' : ['tum phr agaie','w.salam','bara dino bad aie ho'],\n",
        "    'goodbye'  : 'shakal mat dikhaya',\n",
        "    'question': ['ajeeb hon bhai mak', 'Main theek hoon, shukriya!', 'Kya haal hai?'],\n",
        "}"
      ],
      "metadata": {
        "id": "VAjCeSUEAe-o"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**building the training dataset**"
      ],
      "metadata": {
        "id": "qwy_zTOGCe8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = []\n",
        "for intent,examples in intents.items():\n",
        "  for example in examples:\n",
        "    training_data.append((example,intent))"
      ],
      "metadata": {
        "id": "u5UmMHZUCd6i"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Navie Bayes Classifier"
      ],
      "metadata": {
        "id": "9L98v89RD0L3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.classify import NaiveBayesClassifier\n",
        "from nltk.classify.util import accuracy\n",
        "\n",
        "def extract_features(text):\n",
        "  input_tokens = word_tokenize(text.lower())\n",
        "  return {word: word in input_tokens for word in input_tokens}\n",
        "\n",
        "\n",
        "training_features = [(extract_features(text),intent) for (text,intent) in training_data]\n",
        "classifier = NaiveBayesClassifier.train(training_features)\n",
        "print(\"Classifier Accuracy \" , accuracy(classifier,training_features))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_W3bAiLK_ay",
        "outputId": "53b6ab30-73c6-4447-9631-2c440619c18c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier Accuracy  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**define a bot to get response**"
      ],
      "metadata": {
        "id": "_sBqXbYWOuMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "def get_bot_response(user_input):\n",
        "  features=extract_features(user_input)\n",
        "  intent = classifier.classify(features)\n",
        "#  return responses.get(intent)\n",
        "  possible_response =responses.get(intent,['nahi smjha ma'])\n",
        "  return random.choice(possible_response)"
      ],
      "metadata": {
        "id": "Fz-8DSIfOqon"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interaction with User**"
      ],
      "metadata": {
        "id": "VSybpyQnPTn9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "76SkFJQwQwmD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  userinputs = input(\"You : \")\n",
        "  if userinputs.lower() == 'exit':\n",
        "    break\n",
        "  bot_response=get_bot_response(userinputs)\n",
        "  print(\"Bots : \", bot_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIpUrGK9PXoT",
        "outputId": "89bc3c21-5e2c-4631-fb11-8d36830b92cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You : salam\n",
            "Bots :  tum phr agaie\n",
            "You : salam\n",
            "Bots :  w.salam\n",
            "You : salam\n",
            "Bots :  tum phr agaie\n",
            "You : salam\n",
            "Bots :  w.salam\n",
            "You : salam\n",
            "Bots :  bara dino bad aie ho\n",
            "You : salam\n",
            "Bots :  bara dino bad aie ho\n",
            "You : salam\n",
            "Bots :  bara dino bad aie ho\n"
          ]
        }
      ]
    }
  ]
}