{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hasan132002/AI/blob/main/search_blogs_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n30WHrOlw-vR",
        "outputId": "4290c79b-237b-4d97-accf-575834d706f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your search query: الـلّٰـهِ عَـلَيْه\n",
            "No blogs found matching the search criteria.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "\n",
        "class Blog:\n",
        "    def __init__(self, title, content):\n",
        "        self.title = title\n",
        "        self.content = content\n",
        "\n",
        "blogs = [\n",
        "    Blog(\"Blog 1\", \"Dear children! Allah Almighty has ordered us to obey and follow His beloved and final Prophet Muhammad صَلَّى اللهُ عَلَيْهِ وَاٰلِهٖ وَسَلَّم. Even animals, birds, trees, and plants listened to him. The final Prophet صَلَّى اللهُ عَلَيْهِ وَاٰلِهٖ وَسَلَّم was approached by a Bedouin, who asked, “How can I know you are a prophet?” He replied, “What do you think; if I call that branch of that date-palm tree and it comes off, will you bear witness I am a prophet?”  The Bedouin said yes. The Prophet صَلَّى اللهُ عَلَيْهِ وَاٰلِهٖ وَسَلَّم called for it. The branch detached itself, came to the ground, and began hopping towards him. Some narrations even describe it as prostrating as it drew nearer. The Prophet صَلَّى اللهُ عَلَيْهِ وَاٰلِهٖ وَسَلَّم ordered it to return, which it promptly did. Seeing this amazing miracle of the final Prophet صَلَّى اللهُ عَلَيْهِ وَاٰلِهٖ وَسَلَّم, the Bedouin took an oath by Allah, saying that he would believe everything the Prophet صَلَّى اللهُ عَلَيْهِ وَاٰلِهٖ وَسَلَّم told him in the future, and also accepted Islam.\"),\n",
        "    Blog(\"Blog 2\", \"The first Reviver of Islam, ꜤUmar b. Abd al-Aziz رَحْمَةُ الـلّٰـهِ عَـلَيْه was a rightly guided caliph who reigned for two years and five months. He fulfilled his duties as caliph by establishing justice and eradicating oppression across the land. He was given this responsibility without asking for it.[1] A difference exists between asking to rule and being given the responsibility of governance, as explained by the final Prophet صَلَّى اللهُ عَلَيْهِ وَاٰلِهٖ وَسَلَّم when he declared, “O ʿAbd al-Raḥman, son of Samurah! Do not seek to be a ruler, for if you are given authority of ruling without you asking for it, you shall then be helped. If you are given it by your asking, you shall be held responsible (i.e. you will not be helped)\"),\n",
        "    Blog(\"Blog 3\", \"In every era, children usually have a similar carefree attitude. Even at the age of seven or eight years, they cannot reach the depth of any matter. But, unlike other children, the childhood of A’la Hadrat رَحْمَةُ اللهِ عَلَيْه was very outstanding. He was so sensible and had so excellent memory even in the childhood that he succeeded in completing the recitation of the complete Holy Quran in the early age of just 4½ years. At the age of six, he delivered a detailed speech on the topic of Milad-un-Nabi صَلَّى اللهُ عَلَيْهِ وَاٰلِهٖ وَسَلَّم in front of a very large gathering in the blessed month of Rabi’-ul-Awwal and was fully appreciated by the scholars and  saints.At the same age, he رَحْمَةُ اللهِ عَلَيْه got information about the direction of Baghdad (the sacred city of Ghaus-e-A’zam رَحْمَةُ اللهِ عَلَيْه). He رَحْمَةُ اللهِ عَلَيْه then never stretched his legs in that blessed direction out of respect. He رَحْمَةُ اللهِ عَلَيْه was extremely enthusiastic about Salah and would offer the daily five Salahs in Masjid with Takbeer-e-Aula.\"),\n",
        "]\n",
        "\n",
        "def get_synonyms(word):\n",
        "    synonyms = set()\n",
        "    for synset in wordnet.synsets(word):\n",
        "        for lemma in synset.lemmas():\n",
        "            synonyms.add(lemma.name())\n",
        "    return list(synonyms)\n",
        "\n",
        "def expand_query(query):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    query_tokens = word_tokenize(query.lower())\n",
        "    expanded_query = []\n",
        "    for token in query_tokens:\n",
        "        lemmatized_token = lemmatizer.lemmatize(token)\n",
        "        synonyms = get_synonyms(lemmatized_token)\n",
        "        expanded_query.extend(synonyms)\n",
        "    return ' '.join(expanded_query)\n",
        "\n",
        "def search_blogs(query):\n",
        "    expanded_query = expand_query(query)\n",
        "\n",
        "    corpus = [blog.content for blog in blogs]\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform(corpus + [expanded_query])\n",
        "\n",
        "    similarities = cosine_similarity(tfidf_matrix[-1], tfidf_matrix[:-1]).flatten()\n",
        "\n",
        "    most_similar_index = similarities.argmax()\n",
        "\n",
        "    if similarities[most_similar_index] > 0:\n",
        "        return [blogs[most_similar_index]]\n",
        "    else:\n",
        "        return []\n",
        "\n",
        "query = input(\"Enter your search query: \")\n",
        "search_result = search_blogs(query)\n",
        "if search_result:\n",
        "    print(\"Search Results:\")\n",
        "    for blog in search_result:\n",
        "        print(f\"Title: {blog.title}\")\n",
        "        print(f\"Content: {blog.content}\\n\")\n",
        "else:\n",
        "    print(\"No blogs found matching the search criteria.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import nltk\n",
        "import os\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "class Blog:\n",
        "    def __init__(self, title, content):\n",
        "        self.title = title\n",
        "        self.content = content\n",
        "\n",
        "def load_blogs_from_file(file_path):\n",
        "    blogs = []\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        for line in file:\n",
        "            parts = line.strip().split('|')\n",
        "            title = parts[0]\n",
        "            content = parts[1]\n",
        "            blogs.append(Blog(title, content))\n",
        "    return blogs\n",
        "\n",
        "def get_synonyms(word):\n",
        "    synonyms = set()\n",
        "    for synset in wordnet.synsets(word):\n",
        "        for lemma in synset.lemmas():\n",
        "            synonyms.add(lemma.name())\n",
        "    return list(synonyms)\n",
        "\n",
        "# def expand_query(query):\n",
        "#     lemmatizer = WordNetLemmatizer()\n",
        "#     query_tokens = word_tokenize(query.lower())\n",
        "#     expanded_query = []\n",
        "#     for token in query_tokens:\n",
        "#         lemmatized_token = lemmatizer.lemmatize(token)\n",
        "#         synonyms = get_synonyms(lemmatized_token)\n",
        "#         expanded_query.extend(synonyms)\n",
        "#     return ' '.join(expanded_query)\n",
        "\n",
        "def expand_query(query):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    query_tokens = word_tokenize(query.lower())\n",
        "    expanded_query = []\n",
        "    for token in query_tokens:\n",
        "        if token not in stop_words and token not in string.punctuation:\n",
        "            lemmatized_token = lemmatizer.lemmatize(token)\n",
        "            synonyms = get_synonyms(lemmatized_token)\n",
        "            expanded_query.extend([lemmatized_token] + synonyms)\n",
        "    return ' '.join(expanded_query)\n",
        "\n",
        "\n",
        "def search_blogs(query, blogs):\n",
        "    expanded_query = expand_query(query)\n",
        "    corpus = [blog.content for blog in blogs]\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform(corpus + [expanded_query])\n",
        "\n",
        "    similarities = cosine_similarity(tfidf_matrix[-1], tfidf_matrix[:-1]).flatten()\n",
        "\n",
        "    most_similar_index = similarities.argmax()\n",
        "\n",
        "    if similarities[most_similar_index] > 0:\n",
        "        return [blogs[most_similar_index]]\n",
        "    else:\n",
        "        return []\n",
        "\n",
        "def main():\n",
        "    file_path = \"blogs.txt\"\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"Error: File '{file_path}' not found.\")\n",
        "        return\n",
        "\n",
        "    blogs = load_blogs_from_file(file_path)\n",
        "\n",
        "    query = input(\"Enter your search query: \")\n",
        "    search_result = search_blogs(query, blogs)\n",
        "    if search_result:\n",
        "        print(\"Search Results:\")\n",
        "        for blog in search_result:\n",
        "            print(f\"Title: {blog.title}\")\n",
        "            print(f\"Content: {blog.content}\\n\")\n",
        "    else:\n",
        "        print(\"No blogs found matching the search criteria.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plw7WZFwFPQx",
        "outputId": "191c60c8-4a41-4c46-fbaf-aff39a800765"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your search query: blog 7\n",
            "Search Results:\n",
            "Title: Blog 3\n",
            "Content: In every era, children usually have a similar carefree attitude. Even at the age of seven or eight years, they cannot reach the depth of any matter. But, unlike other children, the childhood of A’la Hadrat رَحْمَةُ اللهِ عَلَيْه was very outstanding. He was so sensible and had so excellent memory even in the childhood that he succeeded in completing the recitation of the complete Holy Quran in the early age of just 4½ years. At the age of six, he delivered a detailed speech on the topic of Milad-un-Nabi صَلَّى اللهُ عَلَيْهِ وَاٰلِهٖ وَسَلَّم in front of a very large gathering in the blessed month of Rabi’-ul-Awwal and was fully appreciated by the scholars and  saints.At the same age, he رَحْمَةُ اللهِ عَلَيْه got information about the direction of Baghdad (the sacred city of Ghaus-e-A’zam رَحْمَةُ اللهِ عَلَيْه). He رَحْمَةُ اللهِ عَلَيْه then never stretched his legs in that blessed direction out of respect. He رَحْمَةُ اللهِ عَلَيْه was extremely enthusiastic about Salah and would offer the daily five Salahs in Masjid with Takbeer-e-Aula.\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFQ0/W6WL+fUBNHeTq0IW1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}